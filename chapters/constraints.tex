\chapter{Constraints}

Constraints are the limitations imposed on the system state. They define an allowed setup, that the system can reach. Due to the origin, many types of constraints are distinguished. They can result from system's structure, known trajectory or be directly linked with limitation of mathematical instrument used in the system description.\\

A wide group of constraints is made of geometric constraints, i.e., the constraints that stem directly from the mechanism's structure. They determine the directions in which the mechanism can move so as not to breach the limits imposed by the existence of kinematic pairs.

\section{Selected constrains}

This section presents selected constraints that usually appear in robotics. Every constraint is briefly described and formulated as a function of system's state $\bm{c}(\bm{x})$ (constraint is satisfied when the function is equal to a vector of zeros). In view of its later, use a derivative of constraint function with respect to state $\frac{\partial \bm{c}(\bm{x})}{\partial \bm{x}}$ is also given.

\subsection{Quaternion norm constraint}

A quaternion is defined as four real numbers, and every coefficient is independent. However, when the quaternion is used as a description of orientation, its norm must be equal to 1. Due to the computer's precision, repetitive quaternion rotating applied in the EKF leads to error accumulation and to shrinking or stretching this norm. Moreover, the formula used in the EKF is designed to keep the constant quaternion norm only if the initial quaternion's norm had been equal to 1.\\

In mechanical simulation, this problem is solved by adding an extra pure-synthetic term to the differential equation describing the system \cite{quaternion}. Unfortunately, this method can not be easily adapted in the case of the Kalman Filter. The solution is to treat the quaternion norm equal to 1 as a constraint imposed on the system. Equation (\ref{quat_constraint_fun}) defines the constraint function, and equation (\ref{quat_constraint_fun_der}) defines its derivative. Naturally, the constraint function and its derivative are quaternion-dependent only, and they are scalar functions.

\begin{equation}
	c \left( \bm{q} \right) = \bm{q}^T \bm{q} - 1
\label{quat_constraint_fun}
\end{equation}

\begin{equation}
	\frac{\partial c}{\partial \bm{q}}  \left( \bm{q} \right) = 2\bm{q}^T
	\label{quat_constraint_fun_der}
\end{equation}

\subsection{Position and orientation constraints}

Position and orientation constraints are the constraints that are known before the system moves. They may affect only selected state variables and be applied only at certain times. The general formula that describes this type of constraint is given by equation (\ref{constraint_fun}). The derivative of this function is a mostly-zero matrix with one only on position correlated with the limited state variable.

\begin{equation}
	c \left( \bm{x} \right) = \begin{bmatrix}
		x_i - f\left(t\right) \\
		x_j - g\left(t\right)\\
		\vdots
		\end{bmatrix}
	\label{constraint_fun}
\end{equation} 

The constraints that are given by an entangled function of multiple state variables are usually harder to formulate and require an individual analysis. An example of this type is given in the next section.\\

Another example is a fixation of some parameter that can be calculated from the system state. Assume that the designed mechanism should keep the yaw angle of orientation equal to zero. If the state of the system contains orientation given by a quaternion, the yaw angle can be calculated from the following formula:

\begin{equation}
	\psi = {\mbox{atan2}}\left(2(q_{0}q_{z}+q_{x}q_{y}),1-2(q_{y}^{2}+q_{z}^{2})\right)
\end{equation}

However, the value of \textit{atan2} function is equal to zero if and only if the first argument is equal to zero. With that being said, the simple form of yaw constraint is given by equation (\ref{yaw_constraint_fun}). Equation (\ref{yaw_constraint_fun_der}) defines its derivative. The disadvantage of this approach is that the yaw angle equal to $\pi$ also fulfills the constraint.

\begin{equation}
	c \left( \bm{q} \right) = q_{0}q_{z}+q_{x}q_{y}
	\label{yaw_constraint_fun}
\end{equation}

\begin{equation}
	\frac{\partial c}{\partial \bm{q}}  \left( \bm{q} \right) =
	\begin{bmatrix}
	 q_{z} &  q_{y} &  q_{x} &  q_{0}
	\end{bmatrix}
	\label{yaw_constraint_fun_der}
\end{equation}

\subsection{Distance constraint}

The distance constraint is defined as a constraint that keeps a constant distance between a fixed point in space and a specified point on the moving element. Equation (\ref{distance_constraint_prim}) formalizes the so-defined constraint.

\begin{equation}
	\left| \bm{r}^{(0)} + R(\bm{q})\bm{s}^{(1)} - \bm{r}_p^{(0)} \right| - d = 0
	\label{distance_constraint_prim}
\end{equation}

where:
\begin{itemize}[noitemsep]
	\item $\bm{r}^{(0)}$ -- position of the moving body, given in global coordinate frame,
	\item $R(\bm{q})$ -- rotation matrix between the world frame and the body-fixed frame,
	\item $\bm{s}^{(1)}$ -- position of the selected point on the moving body, given in the body-fixed coordinate system,
	\item $\bm{r}_p^{(0)}$ -- position of the fixed point, given in the global coordinate frame,
	\item d -- the distance between constraint's points.
\end{itemize}

However, the norm of a vector requires calculation of the square root, which value and derivative are more difficult to calculate. Without any loss of generality, the distance constraint can be transformed into the following equation:

\begin{equation}
	c(\bm{r}, \bm{q}) = \left( \bm{r}^{(0)} + R(\bm{q})\bm{s}^{(1)} - \bm{r}_p^{(0)} \right)^T \left( \bm{r}^{(0)} + R(\bm{q})\bm{s}^{(1)} - \bm{r}_p^{(0)} \right) - d^2
	\label{distance_constraint_fun}
\end{equation}

In order to calculate derivative of distance constraint, the MATLAB Symbolic Toolbox was used \mbox{(\textit{distance\_constraint\_derivative.m})}. Equations (\ref{distance_constraint_der1} -- \ref{distance_constraint_der2}) presents calculated partial derivatives with respect to $\bm{r}$ and $\bm{q}$.

\begin{equation}
	\frac{\partial c(\bm{r}, \bm{q})}{r_x} = 2(x - r_{bx} + r_{ax}(2q_0^2 + 2q_x^2 - 1) + r_{ay}(2q_0q_z - 2q_xq_y) + r_{az}(2q_0q_y - 2q_xq_z))^2 
	\label{distance_constraint_der1}
\end{equation}

\begin{equation}
	\frac{\partial c(\bm{r}, \bm{q})}{r_y} = 2(y - r_{by} + r_{ay}(2q_0^2 + 2q_y^2 - 1) + r_{ax}(2q_0q_z + 2q_xq_y) + r_{az}(2q_0q_x + 2q_yq_z))^2
\end{equation}

\begin{equation}
	\frac{\partial c(\bm{r}, \bm{q})}{r_z} = 2(z - r_{bz} + r_{az}(2q_0^2 + 2q_z^2 - 1) + r_{ax}(2q_0q_y + 2q_xq_z) - r_{ay}(2q_0q_x - 2q_yq_z))^2
\end{equation}

\begin{align}
\begin{split}
	\frac{\partial c(\bm{r}, \bm{q})}{q_0} &= 2(2q_yr_{az} - 4q_0r_{ax} + 2q_zr_{ay})(r_{bx} - x - r_{ax}(2q_0^2 + 2q_x^2 - 1)\\
	&+ r_{ay}(2q_0q_z - 2q_xq_y) + r_{az}(2q_0q_y - 2q_xq_z))^2\\
	&+ 2(4q_0r_{ay} +  2q_xr_{az} + 2q_zr_{ax}) \cdot(y - r_{by} + r_{ay}(2q_0^2 + 2q_y^2 - 1)\\
	&+ r_{ax}(2q_0q_z + 2q_xq_y) + r_{az}(2q_0q_x + 2q_yq_z))^2 + 2(4q_0r_{az} - 2q_xr_{ay} + 2q_yr_{ax})\\
	&\cdot(z - r_{bz} + r_{az}(2q_0^2 + 2q_z^2 - 1) + r_{ax}(2q_0q_y + 2q_xq_z) - r_{ay}(2q_0q_x - 2q_yq_z))^2
\end{split}
\end{align}

\begin{align}
\begin{split}
	\frac{\partial c(\bm{r}, \bm{q})}{q_x} &= 2(2q_0r_{az} + 2q_yr_{ax})(y - r_{by} + r_{ay}(2q_0^2 + 2q_y^2 - 1)\\
	&+ r_{ax}(2q_0q_z + 2q_xq_y) + r_{az}(2q_0q_x + 2q_yq_z))^2\\
	&- 2(4q_xr_{ax} + 2q_yr_{ay} + 2q_zr_{az})(r_{bx} - x - r_{ax}(2q_0^2 + 2q_x^2 - 1)\\
	&+ r_{ay}(2q_0q_z - 2q_xq_y) + r_{az}(2q_0q_y - 2q_xq_z))^2 - 2(2q_0r_{ay} - 2q_zr_{ax})\\
	&\cdot(z - r_{bz} + r_{az}(2q_0^2 + 2q_z^2 - 1) + r_{ax}(2q_0q_y + 2q_xq_z) - r_{ay}(2q_0q_x - 2q_yq_z))^2
\end{split}
\end{align}

\begin{align}
	\begin{split}
	\frac{\partial c(\bm{r}, \bm{q})}{q_y} &= 2(2q_xr_{ax} + 4q_yr_{ay} + 2q_zr_{az})(y - r_{by} + r_{ay}(2q_0^2 + 2q_y^2 - 1)\\
	&+ r_{ax}(2q_0q_z + 2q_xq_y) + r_{az}(2q_0q_x + 2q_yq_z))^2\\
	&+ 2(2q_0r_{az} - 2q_xr_{ay})(r_{bx} - x - r_{ax}(2q_0^2 + 2q_x^2 - 1) \\
	&+ r_{ay}(2q_0q_z - 2q_xq_y) + r_{az}(2q_0q_y - 2q_xq_z))^2 + 2(2q_0r_{ax} + 2q_zr_{ay})\\
	&\cdot(z - r_{bz} + r_{az}(2q_0^2 + 2q_z^2 - 1) + r_{ax}(2q_0q_y + 2q_xq_z) - r_{ay}(2q_0q_x - 2q_yq_z))^2
\end{split}
\end{align}

\begin{align}
	\begin{split}
	\frac{\partial c(\bm{r}, \bm{q})}{q_z} &= 2(2q_xr_{ax} + 2q_yr_{ay} + 4q_zr_{az})(z - r_{bz} + r_{az}(2q_0^2 + 2q_z^2 - 1)\\
	&+ r_{ax}(2q_0q_y + 2q_xq_z) - r_{ay}(2q_0q_x - 2q_yq_z))^2\\
	&+ 2(2q_0r_{ay} + 2q_xr_{ax})(r_{bx} - x - r_{ax}(2q_0^2 + 2q_x^2 - 1)\\
	&+ r_{ay}(2q_0q_z - 2q_xq_y) + r_{az}(2q_0q_y - 2q_xq_z))^2 - 2(2q_0r_{ax} - 2q_yr_{ay})\\
	&\cdot(y - r_{by} + r_{ay}(2q_0^2 + 2q_y^2 - 1) + r_{ax}(2q_0q_z + 2q_xq_y) + r_{az}(2q_0q_x + 2q_yq_z))^2
	\label{distance_constraint_der2}
\end{split}
\end{align}
\\

It is worth mentioning that if velocities are known, the equation function (\ref{distance_constraint_fun}) can be differentiated with respect to time to get extra constraint $c(\bm{r}, \bm{q}, \frac{d\bm{r}}{dt}, \frac{d\bm{q}}{dt})$. Nevertheless, the position and velocity are strictly connected within the EKF state function. As a result, the correction of position leads to the correction of velocity.


\section{Inclusion of constraints in the estimation}

Assume that a novel system for locating metro wagons is planned to be developed. The first idea that comes to mind is to use a satellite navigation system, as is usually the case in location-based tasks. However, this solution suffers from a significant flaw: these systems perform much worse underground. The question is whether the quality of the position estimate can be easily improved, and the short answer is yes. A simple assumption that can be made is that metro wagons can only be on the rails. Using the well-known track, it is possible to stick the calculated location to the nearest rails, thus improving its accuracy.
This illustrative example implicitly demonstrates the principle of constraint's correction.\\

The inclusion of constraints in state estimation is not a popular solution. Usually, transform to other state variables that fulfill constraints is suggested. However, it provokes the redesign of the state estimator every time when constraints change. The unique approach is discussed by Dan Simon in articles \cite{simon}, \cite{simon2010kalman} and \cite{simon2006kalman}. It is proposed to add the third phase to the conventional Extended Kalman Filter, as it is shown in figure \ref{ekf_three_phases}.

\begin{figure}[!h]
	\begin{center}
		\begin{tikzpicture}[
			block/.style={rectangle, draw, text width=2cm, text centered, rounded corners, minimum height=1.5cm},
			arrow/.style={->, >=stealth, thick},
			>=Stealth,
			]
			% Nodes
			\node (predict) [block] {Predict};
			\node (correct) [block, right=3cm of predict] {Correction};
			\node (constraints) [block, below left=0.5cm and 0.33cm of correct] {Constraints};
			
			% Arrows
			\draw[bend left=20,-latex] ($(predict.east)+(0,0.3)$) to ($(correct.west)+(0,0.3)$);
			\draw[bend left=40,-latex] (correct.south) to (constraints.east);
			\draw[bend left=40,-latex] (constraints.west) to (predict.south);
			
		\end{tikzpicture}
	\end{center}
	\caption{Stages in the Extended Kalman Filter with constraint correction}
	\label{ekf_three_phases}
\end{figure}

In the constraints correction phase, only the state of the filter changes, and the covariance matrix remains unchanged. For linear constraints $\left( \bm{D} \bm{x} = \bm{d}  \right)$, the following equation presents constraints correction phase:

\begin{equation}
	\bm{\tilde{x}} = \bm{\hat{x}} - \bm{W}^{-1} \bm{D}^T \left( \bm{D} \bm{W}^{-1} \bm{D}^T \right)^{-1} \left( \bm{D} \bm{\hat{x}} - \bm{d}  \right)
	\label{constraint_corr}
\end{equation}

where:
\begin{itemize}[noitemsep]
	\item $\bm{D}$, $\bm{d}$ -- matrix and vector defining linear constraints,
	\item $\bm{W}$ -- square weight matrix,
	\item $\bm{\hat{x}}$ -- filter state before correction,
	\item $\bm{\tilde{x}}$ -- filter state after correction.
\end{itemize}

It is proposed to use the inverse of covariance matrix as the weight matrix  $\bm{W} = \bm{P}^{-1}$. In the case of linear constraints, it leads to the maximum probability
estimate of the state subject to state constraints.\\

Proof of the correctness of this method is well-known in the literature. So as not to duplicate this, another proof will be presented by showing the similarity to Newton-Raphson's nonlinear equations solving method. Assume that $\bm{D}$ is a square matrix with full rank. In order to find the solution of constraint equations, an iterative method is used to solve equation (\ref{Dxd}). The Newton-Rapshon method requires the Jacobi matrix, which in this case is given in equation (\ref{D})

\begin{equation}
	\bm{f} \left( \bm{x} \right) = \left( \bm{D} \bm{x} - \bm{d}  \right)
	\label{Dxd}
\end{equation}

\begin{equation}
	\frac{\partial \bm{f} \left( \bm{x} \right)}{\partial \bm{x}} = \bm{D}
	\label{D}
\end{equation}

According to the Newton-Raphson method, every iteration is given by:
\begin{equation}
	\bm{\tilde{x}} = \bm{\hat{x}} - \left( \frac{\partial \bm{f} \left( \bm{x} \right)}{\partial \bm{x}} \right) ^{-1} \bm{f} \left( \bm{x} \right) = \bm{\hat{x}} - \bm{D}^{-1} \left( \bm{D} \bm{\hat{x}} - \bm{d}  \right)
	\label{NR}
\end{equation}

In general $\bm{D}$ matrix is not square, as there is fewer constraints than the degree of freedom of the mechanisms and $\bm{D}$ can not be inverse trivial. To address this problem right pseudo-inverse can be used (equation (\ref{pseudoinverse})).
\begin{equation}
	\bm{D}^{\#} = \bm{D}^T \left( \bm{D} \bm{D}^T \right) ^ {-1}
	\label{pseudoinverse}
\end{equation}

Furthermore, if the equation is underdetermined, the pseudo-inverse forms a space of proper inverses, scaled by a weight matrix $\bm{W}$:

\begin{equation}
	\bm{D}^{\#} = \bm{W}^{-1} \bm{D}^T \left( \bm{D} \bm{W}^{-1} \bm{D}^T \right) ^ {-1}
	\label{wieight_pseudo}
\end{equation}

Inserting equation (\ref{wieight_pseudo}) to (\ref{NR}) leads to the constraint correction equation (\ref{constraint_corr}).\\

It is worth mentioning that the presented method of calculating the pseudoinverse of D is only valid under the assumption of a full order of the D matrix. The reduction of the order of the matrix occurs when the constraints become linearly dependent. In this situation, another method of calculating pseudo-inversion should be used, e.g, SVD decomposition. \cite{golub2013matrix}\\

The reasoning so far was based on the assumption that constraints are linear. 
However, constraints in mechanic are mostly nonlinear. This problem is addressed by the local linearization method. The following equation define substitutions resulting from linearization:

\begin{equation}
	\bm{D} = \frac{\partial \bm{c}}{\partial \bm{x}}(\bm{\hat{x}})
	\label{linearization1}
\end{equation}

\begin{equation}
	\bm{d} =  - \bm{c} (\bm{\hat{x}}) +  \frac{\partial \bm{c}}{\partial \bm{x}}(\bm{\hat{x}}) \bm{\hat{x}}
	\label{linearization2}
\end{equation}

As a result, the constraint correction method can be used for nonlinear equations.\\ 

Direct application of the method to the discussed problem proved not to work properly and led to instability. However, some improvements were introduced based on the analogy of the constraint correction method to the Newton-Raphson method. The idea behind the proposed enhancement is to divide the correction into many smaller steps. It is proposed to use an additional coefficient $\alpha$ that scales the correction term. By design, the coefficient should be within the range $(0, 1 \rangle $. Next, as the impact of correction was reduced by scaling, it is proposed to conduct the correction multiple times within one run of this phase. This is analogous to the iterations performed by the Newton-Raphson method. The following formula presents the improved constraint correction method with k-times repetition:

\begin{equation}
	\bm{\hat{x}}_{i+1} = \bm{\hat{x}}_{i} - \alpha \bm{P} \bm{D}^T \left( \bm{D} \bm{P} \bm{D}^T \right)^{-1} \left( \bm{D} \bm{\hat{x}} - \bm{d}  \right) \hspace{10pt} \text{for i = 1,2,..,k}
	\label{constraint_final}
\end{equation}

The selection of newly introduced parameters belongs to the tuning, and the correctness and usefulness of the proposed enhancement have been corroborated experimentally.