\chapter{Sensors}

Sensors are the fundamental components of any measurement system, enabling it to perceive the world. There is a vast array of sensor types, each designed to measure specific physical quantities. Even within one type of measured value, sensors can vary significantly in terms of precision and cost. \\

Sensors can generally be classified into two main categories: those that operate independently and those that depend on external infrastructure. Independent sensors operate based on the principles of physics. For example, at its simplest, a temperature sensor exploits the fact that electrical resistance changes with temperature variations. On the other hand, dependent sensors require external resources to function. An example of such a sensor is a GNSS receiver, which estimates its position only when a sufficient number of satellites are visible.\\

Accurately estimating position and orientation typically involves a combination of sensors that measure not only position, velocity, and acceleration but also have an indirect relationship with the state being estimated. The most precise results are achievable when every aspect of the state is directly measured, which is often impractical. The absence of distance sensors and encoders means that state estimation must rely on alternative methods. This thesis will explore dead reckoning, a method that estimates position and orientation by integrating measurements from inertial sensors. At a minimum, this method requires two types of inertial sensors: an accelerometer to measure acceleration and a gyroscope to measure angular velocity. However, results from this minimal setup tend to be suboptimal. In real-world applications, systems are enhanced through redundancy and the incorporation of partial information sources.

\section{Types of sensors}

Sensors measuring a specific type of value, even within the same family, can differ significantly in the methodologies they employ to obtain that value. The development of new sensor types is a constant effort primarily aimed at enhancing accuracy. However, this pursuit of higher accuracy often results in increased sensor costs. It is worthwhile to briefly outline how these methods have evolved over time.\\

For inertial sensors, this evolution can be traced from mechanical sensors to Micro-Electro-Mechanical Systems (MEMS) sensors, and onto todayâ€™s laboratory-grade sensors. Each step on this path not only represents a leap in the technology used but also reflects a balance between achieving greater precision and managing production and operational costs. Mechanical sensors, which were among the first to be developed, rely on mechanical components and physical principles for their operation. Many moving parts often made mechanical sensor unreliable. MEMS sensors, a significant advancement, integrate mechanical components and electronics into a single system, offering improved accuracy, smaller size, and lower power consumption. Today's laboratory-grade sensors, which represent the peak of current technology, provide unparalleled accuracy but at a significantly higher cost. This progression underscores the relentless pursuit of precision in the field of sensor technology, driven by the demands of increasingly sophisticated applications.\\

However, when considering the balance between quality and cost, MEMS sensors are favored in most applications. They guarantee minimal enclosure size and offer quality that is commensurate with their dimensions. Furthermore, the compactness and cost-effectiveness of MEMS sensors make it feasible to deploy arrays of multiple sensors. Integrating their measurements can significantly enhance accuracy. This approach of blending data from multiple MEMS sensors not only improves the precision of measurements but also leverages the strengths of each sensor to compensate for individual limitations, making it a highly efficient strategy in various applications.

\section{Models of sensors}

The description of sensors presented so far has mainly concerned their features and types. However, to use them in an estimation, this description should be enriched with a formalized mathematical model. The sensor model defines the relation between physical quantities and sensor output but also includes an error. A well-prepared model allows the development of better filtration methods and ultimately leads to better results.

\subsection{Accelerometer}

An accelerometer measures all accelerations that affect the sensor. It means that if the sensor is mounted in a non-inertial reference frame, beside the linear acceleration of frame, it will also measure centripetal, angular and Coriolis acceleration. What's more, masses on Earth experience constant gravitational acceleration, and that feature is especially useful in orientation's estimation. An accelerometer measurement is the resultant of those accelerations. Equation (\ref{acc_model1}) represents measured acceleration as a sum of components. Because of its complexity, it is often assumed that the accelerometer is located in the frame center and $\bm{r^W} = \bm{0}$. This leads to a simplification as shown in equation (\ref{acc_model1b}).
\\
\begin{equation}
	\bm{a}_{res}^B = \bm{a}^B + \bm{R}^W_B \left( \bm{\omega}^W \times \left( \bm{\omega}^W \times \bm{r}^W \right) + \bm{\epsilon}^W \times \bm{r}^W + 2\left( \bm{\omega}^W \times \bm{v}^W \right) - \bm{g}  \right)  
	\label{acc_model1}
\end{equation}

\begin{equation}
	\bm{a}_{res}^B = \bm{a}^B - \bm{R}^W_B \left( \bm{g}  \right)  
	\label{acc_model1b}
\end{equation}

where:
\begin{itemize}
	\item $\bm{a}_{res}^B$ -- resultant acceleration given in a moving frame (linked with a body),
	\item $\bm{a}^B$ -- acceleration of the moving frame given in this frame,
	\item $\bm{R}^W_B$ -- rotation matrix from world frame to the moving frame,
	\item $\bm{\omega}^W$ -- the moving frame's angular velocity given in the world frame,
	\item $\bm{\epsilon}^W$ -- the moving frame's angular acceleration given in the world frame,
	\item $\bm{r}^W$ -- sensor position in moving frame given in the world frame,
	\item $\bm{v}^W$ -- the moving frame's linear velocity given in the world frame,
	\item $\bm{g}$ -- gravitation acceleration in the world frame $\left( \bm{g} = \begin{bmatrix}
		0 &  0 &  g
	\end{bmatrix}^T \right)$.
\end{itemize}

The second part of the model provides an inclusion of error. Accelerometers readings are subject to scale error, bias, assembly inaccuracies, and noise.
The scale error means that the readings are linearly dependent on acceleration, but the slope factor is not equal 1 precisely. The bias means that the linear function is not homogeneous and the constant coefficient is non-zero. The assembly inaccuracy is due to the fact that the sensor axes are not collinear with the reference frame. However, the assembly inaccuracy is described as a rotation that does not affect the measure's norm. Finally, the noise is a random component added to measure. Fortunately, in the case of an accelerometer, the noise is negligibly small. Equation (\ref{acc_model2}) describe the correlation between acceleration and output from the sensor.\\


\begin{equation}
	\bm{\hat{a}}_{res}^B = \bm{R}_M \bm{S} \left( \bm{a}_{res}^B + \bm{b}_0 \right) + \bm{n}
	\label{acc_model2}
\end{equation}

where:
\begin{itemize}
	\item $\bm{\hat{a}}_{res}^B$ -- accelerometer output,
	\item $\bm{R}_M$ -- rotation matrix due to assembly inaccuracy,
	\item $\bm{S}$ -- diagonal scale matrix,
	\item $\bm{b}_0$ -- sensor constant bias,
	\item $\bm{n}$ -- random noise.	
\end{itemize}



\subsection{Gyroscope}
A gyroscope is a sensor designed to measure angular velocities. An angular velocity characterizes the whole moving body. Thus, the gyroscope readings are independent of the sensor position within the moving reference frame.\\

The primary advantage of a gyroscope lies in its ability to measure raw angular velocities. However, it's important to note that this measurement is not direct; for example, in MEMS sensors, the measurement is based on the transfer of energy between two vibration modes caused by the Coriolis acceleration \cite{passaro2017gyroscope}.\\

Despite its advantages, a gyroscope's measurements are susceptible to various errors. Two significant sources of error are bias and drift. Bias refers to a constant offset in the measured values, which is inherent to the sensor and remains relatively stable over time. Drift, on the other hand, is the gradual change in sensor offset over time, leading to a continuously growing deviation from the true value. In addition to bias and drift, gyroscopes are also affected by high-frequency noise, which can obscure the true signal. The following equation presents a mathematical model of a gyroscope.

\begin{equation}
	\bm{\hat{\omega}}^B = \bm{\omega}^B + \bm{b}(t) + \bm{b}_0 + \bm{h}
	\label{gyro_model}
\end{equation}

where:
\begin{itemize}
	\item $\bm{\hat{\omega}}^B$ -- gyroscope's output,
	\item $\bm{\omega}^B$ -- moving frame angular velocity given in moving reference frame,
	\item $\bm{b}(t)$ -- drift -- the part of sensor offset that change over time,
	\item $\bm{b}_0$ -- the constant part of sensor offset,
	\item $\bm{h}$ -- high-frequency random noise.
\end{itemize}

While bias presence is inevitable in gyroscopes, it is crucial to monitor and account for drift, as it can significantly affect the accuracy of long-term measurements. Understanding and mitigating these errors are essential for ensuring the reliable performance of gyroscopes in various applications.\\

Finally, it is worth mentioning why the assembly inaccuracies are not included in the sensor model. Obviously, a gyroscope can be mounted improperly, but the effects of this flaw can be included in bias. What will transpire later, the gyroscope is not used in absolute orientation estimation, and its error is compensated.

\subsection{External position and orientation provider}

External provides supply additional data that can appear to be useful in further estimation. There are many sources providing various measurements. Some of them deliver only partial information, while others can estimate a full description of the system. However, the measurements may be low-precise or too slowly updated to be used alone as an estimation.\\

An example considered in this project is the use of the robot's end-effector position calculated by its control system. The industrial robot acquires end-effector position by calculating forward kinematics based on encoder readings and knowledge about the robot's structure. The orientation of the end-effector is also calculated and can be used in the estimation if the connection between the robot's arm and the mechanism is rigid. Within the scope of this work, the data from the external provider should be identified with the data from the industrial robot control system.\\

The model of an external provider, treated as a sensor, is not as straightforward as the models presented so far. Many factors are involved, including the position and type of connection between the end-effector and mechanism, their relative positions, and the accuracy of the robotâ€™s calculation. Moreover, accuracy is not always directly specified because, for industrial robots, repeatability is much more important than precision \cite{shiakolas2002accuracy}. It is always reasonable to assume that readings include additional noise.\\

Assume that the robot's end-effector is connected with the origin of the moving coordinate frame with a rigid drawbar. The drawbar is double-ended with spherical joints, so the orientation of the end-effector does not affect the driven system. In this case, the position provided by the robot's control system is a composition of the moving frame origin's position, and the translation is inserted by the drawbar. The following equation presents the relation between the origin's position and the end-effector position when the length and orientation of the drawbar are known.

\begin{equation}
	\begin{bmatrix}
		x_t \\ y_t \\ z_t 
	\end{bmatrix}
	=
	\begin{bmatrix}
		x \\ y \\ z 
	\end{bmatrix}
	+
	\bm{R}_z \left( \zeta \right)
	\bm{R}_y \left( \eta \right)
	\begin{bmatrix}
		d \\ 0 \\ 0 
	\end{bmatrix}
	\label{drawbar_model}
\end{equation}

where:
\begin{itemize}
	\item $x_t$, $y_t$, $z_t$ -- components of the end-effector's position,
	\item $x$, $y$, $z$ -- components of the origin's position,
	\item $d$ -- the length of the drawbar,
	\item $\zeta$, $\eta$ -- a description of the drawbar's orientation. The $\eta$ is an elevation, the angle between the drawbar's translation vector and OXY world plane. The $\zeta$ is an azimuth, the angle between the drawbar's translation vector's projection on OXY plane and OX axis.
\end{itemize}



\section{Sensor calibration and filtration}



\subsection{Accelerometer}

Accelerometer calibration aims to remove a bias and compensate for the effects of an assembly inaccuracy and a scale error. The accelerometer's noise compensation is usually moved to sensor fusion. Before proposing a calibration method, the model given in equation (\ref{acc_model2}) can be transformed into the following equation. The noise is ignored, while the product $\bm{R}_M$ $\bm{S}$ is treated as an inverse of a new coefficient matrix $\bm{\varPhi}$. The proof that the product of matrices $\bm{R}_M$ and $\bm{S}$ is the inverse of some $3 \times 3$ matrix $\bm{\varPhi}$ is that the rotation matrix is orthogonal, and the scale matrix is diagonal. Both these matrices are non-singular, so their product can also be inverted.

\begin{equation}
	\bm{\hat{a}}_{res}^B \approx \bm{\varPhi}^{-1} \left( \bm{a}_{res}^B + \bm{b}_0 \right)
	\label{acc_calib}
\end{equation}

That being said, calibration model is proposed as:

\begin{equation}
	\bm{\tilde{a}}_{res}^B = \bm{\varPhi} \bm{\hat{a}}_{res}^B - \bm{b}_0 = \bm{\varPhi} \bm{\hat{a}}_{res}^B + \bm{\varGamma}
	\label{acc_calib2}
\end{equation}

where:
\begin{itemize}
	\item $\bm{\tilde{a}}_{res}^B$ -- calibrated accelerometer's output,
	\item $\bm{\varPhi}$ -- $3 \times 3$ calibration's coefficient matrix,
	\item $\bm{\varGamma}$ -- $3 \times 1$ calibration's coefficient vector.
\end{itemize}
As a result, the accelerometerâ€™s calibration comes down to finding values of $3 \cdot 3 + 3 = 12$ coefficients. To achieve this, readings are collected when the sensor is in positions for which the expected values are known. An accelerometer, even if not moving, measures gravitational acceleration. Assume that the sensor is closed in the box and that the edges are parallel to its coordinates system. When the box rests on each of its faces on a flat table, the accelerometer is expected to measure $\begin{bmatrix}\pm g & 0 & 0\end{bmatrix}^T$, $\begin{bmatrix}0 & \pm g & 0\end{bmatrix}^T$ or $\begin{bmatrix} 0 & 0 \pm g\end{bmatrix}^T$. Therefore, collecting measures from every face results in $6 \cdot 3 = 18$ equations that can be used to determine the values of calibration coefficients. As there are more equations than unknowns, the linear regression method is used. In this work, it was decided to utilize the Ordinary Least Squares method (OLS). Before the method is applied, all the equations have to be transformed to a linear form given in the following equation.
\begin{equation}
	\bm{X} \bm{\varTheta} = \bm{Y}
	\label{ols}
\end{equation}
where:
\begin{itemize}
	\item $\bm{X}$ -- n x m known matrix,
	\item $\bm{\varTheta}$ -- m x 1 vector whose value is estimated,
	\item $\bm{Y}$ -- n x 1 known matrix.
\end{itemize}
 
The transformation to linear form is given in the following:
\setcounter{MaxMatrixCols}{25}

\begin{equation}
	\bm{\varTheta} = \begin{bmatrix} \varPhi_{11} & \varPhi_{12} & \varPhi_{13} & \varGamma_1 & \varPhi_{21} & \varPhi_{22} & \varPhi_{23} & \varGamma_2 & \varPhi_{31} & \varPhi_{32} & \varPhi_{33} & \varGamma_3 \\
	\end{bmatrix}^T
	\label{ols_theta}
\end{equation}


\begin{equation}
	\bm{Y} = \begin{bmatrix} 0 & 0 & g & \vdots & 0 & 0 & -g & \vdots & g & 0 & 0 & \vdots & -g & 0 & 0  & \vdots& 0 & g & 0 & \vdots & 0 & -g & 0 \\
	\end{bmatrix}^T
	\label{ols_y}
\end{equation}

\begin{equation}
	\bm{X} = 
	\begin{bmatrix}
	\bm{a}^T_T & 1 & \bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{a}^T_T & 1 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0 & \bm{a}^T_T & 1\\
	
	\bm{a}^T_D & 1 & \bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{a}^T_D & 1 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0 & \bm{a}^T_D & 1\\
	
	\bm{a}^T_F & 1 & \bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{a}^T_F & 1 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0 & \bm{a}^T_F & 1\\
	
	\bm{a}^T_B & 1 & \bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{a}^T_B & 1 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0 & \bm{a}^T_B & 1\\
	
	\bm{a}^T_R & 1 & \bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{a}^T_R & 1 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0 & \bm{a}^T_R & 1\\
	
	\bm{a}^T_L & 1 & \bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{a}^T_L & 1 & \bm{0}_{1 \times 3} & 0\\
	\bm{0}_{1 \times 3} & 0 & \bm{0}_{1 \times 3} & 0 & \bm{a}^T_L & 1\\
	\end{bmatrix} 
	\label{ols_x}
\end{equation}
where:
\begin{itemize}
	\item $\bm{a}_T$ -- measurement the box is top face up,
	\item $\bm{a}_D$ -- measurement the box is down face up,
	\item $\bm{a}_F$ -- measurement the box is front face up,
	\item $\bm{a}_B$ -- measurement the box is back face up,
	\item $\bm{a}_R$ -- measurement the box is right face up,
	\item $\bm{a}_L$ -- measurement the box is left face up.
\end{itemize}

According to OLS method, estimation $\bm{\hat{\varTheta}}$ is given by:

\begin{equation}
	\bm{\hat{\varTheta}} = \left( \bm{X}^T \bm{X} \right)^{-1} \bm{X}^T \bm{Y}
	\label{ols_est}
\end{equation}

Ultimately, the result is decomposed into $\bm{\varPhi}$ and $\bm{\varGamma}$. An intuitive procedure of collecting calibration measures is also part of the system. Usually, accelerometer calibration involves placing the sensor on the calibration table and approving the measure (for example, by clicking a button). Moreover, in certain systems, the order of sides that are being measured is predetermined. This approach has a fundamental advantage because it recognizes sensors mounted in any orientation. Nevertheless, if the sensor is roughly set properly (axes are directed in accordance but not perfectly aligned), the calibration process can be improved by recognizing which face sensor was plated. For this purpose, sensor measurements are collected into statistics that calculate the mean value and standard deviation. If the standard deviation is below a predefined threshold, the sensor is not moving. Next, the mean value is normalized and compared with every 6 axesâ€™ unit vectors. If the angle between the normalized mean and the unit vector is less than specified (that can be quickly checked using the dot product), the face correlated with the unit vector is recognized.



\subsection{Gyroscope}

The gyroscope readings contain bias and high-frequency noise. The constant component of bias can be calculated and removed in calibration. After the sensor starts, the gyroscope readings are collected for a specified period, and a statistic is created. Next, the mean and standard deviation are calculated. If the standard deviation is small enough, it is assumed that the sensor is not broken and it was not moved during the calibration. In the opposite case, the calibration is repeated. The mean is a calculated bias that will be subtracted from the reading. Unfortunately, there is no method that can remove the drift before the system runs. However, the drift tracking and correction can be a part of sensor fusion that will be presented further.


Moving on, the noise is removed by passing reading through filters. Low-pass filters are used to remove high-frequency noise. They are characterized by a cutoff frequency and an order. The cutoff frequency is the limit beyond which the higher-frequency signal is dampened. The filterâ€™s order defines the slope factor of this dampening. The first-order low-pass filter is given by the equations that follow. If readings are collected with a constant sampling rate, $\alpha$ coefficient is calculated only once.

\begin{equation}
	 \alpha = e^{ - \omega_{cf} \varDelta t}
	\label{lpf_alpha}
\end{equation}

\begin{equation}
	\bm{\tilde{\omega}}^B(t) = \alpha  \bm{\hat{\omega}}^B(t) + \left( 1 - \alpha \right) \bm{\hat{\omega}}^B(t - \varDelta t)
	\label{lpf}
\end{equation}

where:
\begin{itemize}
	\item $\bm{\tilde{\omega}}^B$ -- filtered angular velocity,
	\item $\omega_{cf}$ -- cut-off frequency,
	\item $\varDelta t$ -- sampling interval.
\end{itemize}

Proper frequency selection requires involving multiple factors. If noise bandwidth was not specified by the sensor producer, the frequency can be selected by analyzing logs. Assume that the gyroscope was collecting data (without filtration) when the mechanism was moving along the determined trajectory, and for this trajectory, the expected velocities are known. Next, spectral transform is conducted for registered data and expectations. The noise spectrum can be obtained by subtraction spectrums from the last step. Ultimately, the cut-off frequency should be placed above the highest frequency in the expectation spectrum and below the lowest frequency in the noise spectrum.\\

It should be mentioned that -- in specific cases -- it is rewarding to use bandpass filters instead of low-pass filters. The advantage of this approach is that the bandpass filter removes high-frequency noise as well as bias. However, the measured signal often overlaps the bias bandwidth, and using such a filter leads to insensitivity to low velocities. To summarize, this solution should only be implemented if an active drift correction is impossible or only high velocities are important for research.


